{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN18jEAT2f/ougyt0/a2pOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahfujul-01726/Random/blob/main/SynergyX2024_Datathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier  # Use RandomForestRegressor for regression tasks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report  # For classification tasks\n",
        "from sklearn.impute import SimpleImputer  # For imputing missing target values\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['v16'], errors='ignore')  # Feature matrix without target column\n",
        "y = data['v16'] if 'v16' in data.columns else None  # Target variable\n",
        "\n",
        "# Drop non-numeric columns from features, assuming 'id' is retained separately for later merging\n",
        "X_numeric = X.select_dtypes(include=[int, float])\n",
        "\n",
        "# Impute missing values in the feature matrix using the mean (for numeric features)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_numeric)\n",
        "\n",
        "# Initialize the SimpleImputer for the target variable 'v16' (impute with the most frequent class)\n",
        "y_imputer = SimpleImputer(strategy='most_frequent')  # For classification, you can also use 'mean' for regression\n",
        "y_imputed = y_imputer.fit_transform(data[['v16']])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_imputed.ravel(), test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Classifier (use RandomForestRegressor if it's a regression task)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # Adjust parameters as needed\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model (for classification)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# If it's a regression problem, you can use the following metrics instead:\n",
        "# from sklearn.metrics import mean_squared_error, r2_score\n",
        "# print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "# print(\"R^2 Score:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kM1tMdxsxcK",
        "outputId": "e06d54ee-bed7-4784-ccd4-45a106b10be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9772685196364895\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99    121237\n",
            "         1.0       0.89      0.07      0.12      2996\n",
            "\n",
            "    accuracy                           0.98    124233\n",
            "   macro avg       0.93      0.53      0.56    124233\n",
            "weighted avg       0.98      0.98      0.97    124233\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0AOIa_lKMsPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wqkol32_k1az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting"
      ],
      "metadata": {
        "id": "kF_SKEn23miK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset correctly\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['v16'], errors='ignore')  # Feature matrix without target column\n",
        "y = data['v16'] if 'v16' in data.columns else None  # Target variable\n",
        "\n",
        "# Identify non-numeric columns\n",
        "non_numeric_cols = X.select_dtypes(exclude=[int, float]).columns\n",
        "print(\"Non-numeric columns:\", non_numeric_cols)\n",
        "\n",
        "# Apply Label Encoding for non-numeric columns (if needed for ordinal data)\n",
        "label_encoder = LabelEncoder()\n",
        "for col in non_numeric_cols:\n",
        "    X[col] = label_encoder.fit_transform(X[col])\n",
        "\n",
        "# Select only numeric columns (now encoded if non-numeric)\n",
        "X_numeric = X.select_dtypes(include=[int, float])\n",
        "\n",
        "# Impute missing values in the feature matrix using the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_numeric)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply PCA to retain 95% of the variance\n",
        "pca = PCA(0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Impute missing values in the target variable 'v16' using RandomForestClassifier\n",
        "if y is not None:\n",
        "    if y.isna().any():\n",
        "        # Separate rows with and without missing values in y\n",
        "        X_no_nan = X_pca[y.notna()]  # Rows without missing values in y\n",
        "        y_no_nan = y.dropna()        # Target values without NaN\n",
        "        X_nan = X_pca[y.isna()]      # Rows with missing values in y\n",
        "\n",
        "        # Train a classifier to predict missing values\n",
        "        classifier = RandomForestClassifier(random_state=42)\n",
        "        classifier.fit(X_no_nan, y_no_nan)\n",
        "\n",
        "        # Predict missing values in y and impute them\n",
        "        y_pred_nan = classifier.predict(X_nan)\n",
        "        y_imputed = y.copy()\n",
        "        y_imputed.loc[y.isna()] = y_pred_nan\n",
        "    else:\n",
        "        y_imputed = y  # No missing values in y\n",
        "else:\n",
        "    print(\"Target variable 'v16' not found.\")\n",
        "    y_imputed = None\n",
        "\n",
        "# Apply SMOTE to the PCA-transformed data and the imputed target variable\n",
        "if y_imputed is not None:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_pca, y_imputed)\n",
        "\n",
        "    # Create a DataFrame for the resampled data\n",
        "    pca_columns = [f'PC{i+1}' for i in range(X_resampled.shape[1])]\n",
        "    X_resampled_df = pd.DataFrame(data=X_resampled, columns=pca_columns)\n",
        "    y_resampled_df = pd.Series(y_resampled, name='v16')\n",
        "\n",
        "    # Combine the resampled PCA components with the target variable\n",
        "    final_df = pd.concat([X_resampled_df, y_resampled_df.reset_index(drop=True)], axis=1)\n",
        "else:\n",
        "    print(\"Target variable 'v16' is not available for resampling with SMOTE.\")\n",
        "\n",
        "# Output the final DataFrame\n",
        "print(\"Resampled DataFrame with balanced target variable:\\n\", final_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rSghufFwYRX",
        "outputId": "2e17dfb9-62ae-4201-f550-679dae7d157c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-numeric columns: Index(['v15', 'v39', 'v41', 'v42'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "nan_check = final_df.isna().sum().sum()\n",
        "\n",
        "# If nan_check > 0, there are missing values in the dataset\n",
        "if nan_check > 0:\n",
        "    print(f\"The dataset contains {nan_check} missing values.\")\n",
        "else:\n",
        "    print(\"The dataset contains no missing values.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N84lovXRk1VZ",
        "outputId": "406537df-4bec-42d9-94f0-6f9dadf7ba92"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains no missing values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example: Assume 'data' is your DataFrame and 'target_column' is the column you want to check\n",
        "value_counts = final_df['v16'].value_counts()\n",
        "print(value_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLsZlMLVtWnb",
        "outputId": "bc8ae373-32bf-441a-ae06-a51ac4d2550a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v16\n",
            "0.0    566545\n",
            "1.0    566545\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Remove the target variable 'v16' if it exists\n",
        "data_without_target = data.drop(columns=['v16'], errors='ignore')\n",
        "\n",
        "# Identify non-numeric columns\n",
        "non_numeric_cols = data_without_target.select_dtypes(exclude=[int, float]).columns\n",
        "print(\"Non-numeric columns:\", non_numeric_cols)\n",
        "\n",
        "# Apply Label Encoding for non-numeric columns\n",
        "label_encoder = LabelEncoder()\n",
        "for col in non_numeric_cols:\n",
        "    data_without_target[col] = label_encoder.fit_transform(data_without_target[col])\n",
        "\n",
        "# Impute missing values in the dataset using the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_imputed = imputer.fit_transform(data_without_target)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_imputed)\n",
        "\n",
        "# Apply PCA to retain 95% of the variance\n",
        "pca = PCA(0.95)\n",
        "data_pca = pca.fit_transform(data_scaled)\n",
        "\n",
        "# Create a DataFrame with the principal components\n",
        "pca_columns = [f'PC{i+1}' for i in range(data_pca.shape[1])]\n",
        "data_pca_df = pd.DataFrame(data=data_pca, columns=pca_columns)\n",
        "\n",
        "# Combine with the original 'id' column if it exists\n",
        "if 'id' in data.columns:\n",
        "    final_df1 = pd.concat([data[['id']].reset_index(drop=True), data_pca_df], axis=1)\n",
        "else:\n",
        "    print(\"Warning: 'id' column not found in the original data. Proceeding without it.\")\n",
        "    final_df1 = data_pca_df\n",
        "\n",
        "# Output the final DataFrame\n",
        "print(final_df1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v0qFfCf0-PR",
        "outputId": "a0006837-0e7b-4524-9217-c2564178080d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-numeric columns: Index(['v15', 'v39', 'v41', 'v42'], dtype='object')\n",
            "            id       PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
            "0            1  1.432645 -0.944836 -1.075168 -0.808539 -0.292322 -1.958712   \n",
            "1            2 -2.035477 -1.778049  0.868146  0.873947 -0.002807 -0.064939   \n",
            "2            3  5.343929  2.460963  0.656341  1.147806 -0.089056 -2.395672   \n",
            "3            4  1.810176  3.296826  0.021966  0.300480 -0.149771 -1.026782   \n",
            "4            5  3.923146  0.778475  0.062735  0.265831  0.056479 -0.341798   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "186729  186730 -0.706463 -1.396845  1.504251  1.444677  0.161426  0.540021   \n",
            "186730  186731 -0.335514 -2.439772  0.482738  0.486245  0.097402  0.052223   \n",
            "186731  186732  0.177281  0.094525 -1.510632 -1.817764  0.157714 -0.105115   \n",
            "186732  186733 -0.017424  2.528710  0.905368  0.949250  0.047906 -0.310260   \n",
            "186733  186734  2.833654  1.776910  3.467190  3.628133  0.274323  1.096916   \n",
            "\n",
            "             PC7       PC8       PC9  ...      PC34      PC35      PC36  \\\n",
            "0      -0.029489 -1.192433  0.155545  ...  0.017011 -0.279802 -0.724920   \n",
            "1      -0.133071  0.292498  0.033963  ...  0.444471  0.468546 -0.442602   \n",
            "2       0.067988 -0.227901 -0.026483  ... -0.471142  0.044848 -0.198883   \n",
            "3       0.285526 -0.940144  0.670447  ...  0.224227 -0.237720  0.748640   \n",
            "4       0.107337 -0.081776  0.107048  ... -0.340051  0.560231  0.389106   \n",
            "...          ...       ...       ...  ...       ...       ...       ...   \n",
            "186729  0.100564  1.101124 -0.915459  ... -1.185485 -0.461367 -0.054941   \n",
            "186730 -0.156977  0.979145  0.153405  ... -1.586741  0.039791  0.641401   \n",
            "186731 -0.144902  0.176077 -1.606903  ...  0.433297 -1.137505  0.551466   \n",
            "186732  0.201234 -0.176575 -0.886906  ...  0.478995 -1.026223  0.667909   \n",
            "186733  0.192724  1.123108 -0.171062  ...  0.194996  0.481375  1.136967   \n",
            "\n",
            "            PC37      PC38      PC39      PC40      PC41      PC42      PC43  \n",
            "0       0.087867 -0.171456 -0.016014 -0.260450 -0.073161  0.175194 -0.071032  \n",
            "1       0.374325 -0.092490  0.055753  0.349078 -0.268777 -0.018878  0.009722  \n",
            "2      -0.556492  0.139632 -0.012764 -0.059833 -0.511070  0.177208  0.126413  \n",
            "3      -0.799077 -0.199756 -0.063317  0.181816 -0.549935 -0.097963 -0.009838  \n",
            "4      -0.264116 -0.096689 -0.019873 -0.358548  0.362635 -0.089174 -0.126723  \n",
            "...          ...       ...       ...       ...       ...       ...       ...  \n",
            "186729  0.712611 -0.532984 -0.067512 -0.317207  0.483909  0.093160 -0.154354  \n",
            "186730 -1.150436  0.468685 -0.068262  0.404801 -0.796368 -0.057823  0.157997  \n",
            "186731 -0.126917 -0.569348 -0.031432  0.247115 -0.115638  0.117398  0.115406  \n",
            "186732  0.922025 -0.783744 -0.022302 -0.039757  0.732138  0.199197 -0.109218  \n",
            "186733 -0.275983  0.071963 -0.006727  0.735135 -2.028939 -0.321425  0.442480  \n",
            "\n",
            "[186734 rows x 44 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Separate features and target variable in both training and testing datasets\n",
        "X_train = final_df.drop(columns=['v16'], errors='ignore')  # Features from training set\n",
        "y_train = final_df['v16']  # Target from training set\n",
        "\n",
        "X_test = final_df1.drop(columns=['v16'], errors='ignore')  # Features from testing set\n",
        "y_test = final_df1['v16']  # Target from testing set\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "classifier = RandomForestClassifier(random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Output results\n",
        "print(f\"Accuracy on the test dataset: {accuracy:.4f}\")\n",
        "print(\"Classification Report on the test dataset:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_yN4Re3T0-M_",
        "outputId": "aade4bbe-49bb-4d8a-eb65-6dca882c4d84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'final_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c81a7760affb>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Separate features and target variable in both training and testing datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v16'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Features from training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v16'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Target from training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GiaTjNgFuzJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S2_6hNmSuzGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQuY8VdTtIiv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}