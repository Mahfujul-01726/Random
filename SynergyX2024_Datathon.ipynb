{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWftLyW6D7me8riHMOu5Bo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahfujul-01726/Random/blob/main/SynergyX2024_Datathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier  # Use RandomForestRegressor for regression tasks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report  # For classification tasks\n",
        "from sklearn.impute import SimpleImputer  # For imputing missing target values\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['v16'], errors='ignore')  # Feature matrix without target column\n",
        "y = data['v16'] if 'v16' in data.columns else None  # Target variable\n",
        "\n",
        "# Drop non-numeric columns from features, assuming 'id' is retained separately for later merging\n",
        "X_numeric = X.select_dtypes(include=[int, float])\n",
        "\n",
        "# Impute missing values in the feature matrix using the mean (for numeric features)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_numeric)\n",
        "\n",
        "# Initialize the SimpleImputer for the target variable 'v16' (impute with the most frequent class)\n",
        "y_imputer = SimpleImputer(strategy='most_frequent')  # For classification, you can also use 'mean' for regression\n",
        "y_imputed = y_imputer.fit_transform(data[['v16']])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_imputed.ravel(), test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Classifier (use RandomForestRegressor if it's a regression task)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # Adjust parameters as needed\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model (for classification)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# If it's a regression problem, you can use the following metrics instead:\n",
        "# from sklearn.metrics import mean_squared_error, r2_score\n",
        "# print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "# print(\"R^2 Score:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kM1tMdxsxcK",
        "outputId": "e06d54ee-bed7-4784-ccd4-45a106b10be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9772685196364895\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99    121237\n",
            "         1.0       0.89      0.07      0.12      2996\n",
            "\n",
            "    accuracy                           0.98    124233\n",
            "   macro avg       0.93      0.53      0.56    124233\n",
            "weighted avg       0.98      0.98      0.97    124233\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0AOIa_lKMsPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wqkol32_k1az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting"
      ],
      "metadata": {
        "id": "kF_SKEn23miK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # final_df=train"
      ],
      "metadata": {
        "id": "Wv_tZwUi4WbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset correctly\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['v16'], errors='ignore')  # Feature matrix without target column\n",
        "y = data['v16'] if 'v16' in data.columns else None  # Target variable\n",
        "\n",
        "# Identify non-numeric columns\n",
        "non_numeric_cols = X.select_dtypes(exclude=[int, float]).columns\n",
        "print(\"Non-numeric columns:\", non_numeric_cols)\n",
        "\n",
        "# Apply Label Encoding for non-numeric columns (if needed for ordinal data)\n",
        "label_encoder = LabelEncoder()\n",
        "for col in non_numeric_cols:\n",
        "    X[col] = label_encoder.fit_transform(X[col])\n",
        "\n",
        "# Select only numeric columns (now encoded if non-numeric)\n",
        "X_numeric = X.select_dtypes(include=[int, float])\n",
        "\n",
        "# Impute missing values in the feature matrix using the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X_numeric)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Apply PCA to retain 95% of the variance\n",
        "pca = PCA(0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Impute missing values in the target variable 'v16' using RandomForestClassifier\n",
        "if y is not None:\n",
        "    if y.isna().any():\n",
        "        # Separate rows with and without missing values in y\n",
        "        X_no_nan = X_pca[y.notna()]  # Rows without missing values in y\n",
        "        y_no_nan = y.dropna()        # Target values without NaN\n",
        "        X_nan = X_pca[y.isna()]      # Rows with missing values in y\n",
        "\n",
        "        # Train a classifier to predict missing values\n",
        "        classifier = RandomForestClassifier(random_state=42)\n",
        "        classifier.fit(X_no_nan, y_no_nan)\n",
        "\n",
        "        # Predict missing values in y and impute them\n",
        "        y_pred_nan = classifier.predict(X_nan)\n",
        "        y_imputed = y.copy()\n",
        "        y_imputed.loc[y.isna()] = y_pred_nan\n",
        "    else:\n",
        "        y_imputed = y  # No missing values in y\n",
        "else:\n",
        "    print(\"Target variable 'v16' not found.\")\n",
        "    y_imputed = None\n",
        "\n",
        "# Apply SMOTE to the PCA-transformed data and the imputed target variable\n",
        "if y_imputed is not None:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_pca, y_imputed)\n",
        "\n",
        "    # Create a DataFrame for the resampled data\n",
        "    pca_columns = [f'PC{i+1}' for i in range(X_resampled.shape[1])]\n",
        "    X_resampled_df = pd.DataFrame(data=X_resampled, columns=pca_columns)\n",
        "    y_resampled_df = pd.Series(y_resampled, name='v16')\n",
        "\n",
        "    # Combine the resampled PCA components with the target variable\n",
        "    final_df = pd.concat([X_resampled_df, y_resampled_df.reset_index(drop=True)], axis=1)\n",
        "else:\n",
        "    print(\"Target variable 'v16' is not available for resampling with SMOTE.\")\n",
        "\n",
        "# Output the final DataFrame\n",
        "print(\"Resampled DataFrame with balanced target variable:\\n\", final_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rSghufFwYRX",
        "outputId": "2e17dfb9-62ae-4201-f550-679dae7d157c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-numeric columns: Index(['v15', 'v39', 'v41', 'v42'], dtype='object')\n",
            "Resampled DataFrame with balanced target variable:\n",
            "               PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
            "0       -1.917209 -0.148872  0.516312  0.900320 -0.179700 -2.005388 -0.220570   \n",
            "1        1.331313  1.845028  0.879955  1.764853 -0.310367 -0.228063  0.335680   \n",
            "2       -2.782442 -0.114113 -0.260353 -0.124727 -0.317031 -2.491713 -0.176647   \n",
            "3       -1.265401  2.236560 -0.135987 -0.078908  0.164585  1.105585  0.600814   \n",
            "4       -1.428050  0.589388  1.320871  2.083077 -0.129150  0.269370  0.069195   \n",
            "...           ...       ...       ...       ...       ...       ...       ...   \n",
            "1133085 -0.894332 -2.589127  0.478656  0.473043  0.059328  0.580407 -0.201536   \n",
            "1133086  3.062639 -4.250206  0.176884  0.384854 -0.079298 -1.788413 -0.466390   \n",
            "1133087  3.457507 -3.530111 -0.361433 -0.406244  0.059948  1.009309 -0.044757   \n",
            "1133088 -1.685137 -2.718116 -1.167727 -1.834311  0.039681  0.108309  0.092071   \n",
            "1133089  0.570178 -2.721374 -0.448598 -0.297927 -0.273142 -1.258319  0.121591   \n",
            "\n",
            "              PC8       PC9      PC10  ...      PC36      PC37      PC38  \\\n",
            "0        1.505057 -0.567750  0.623822  ...  0.409423 -0.084549  0.286551   \n",
            "1       -1.281619  0.694336  1.064331  ...  0.272554  0.114504 -0.046566   \n",
            "2        1.325774 -0.056261  0.793046  ...  0.296294  0.202783 -0.004841   \n",
            "3       -3.747250  1.801643 -2.543493  ... -0.168327 -0.138793  0.112667   \n",
            "4       -0.099356 -0.469625  0.692391  ...  0.401219 -1.375309  1.464443   \n",
            "...           ...       ...       ...  ...       ...       ...       ...   \n",
            "1133085  1.232096  0.110164  0.279770  ... -1.147160  0.239604 -0.383825   \n",
            "1133086  1.428119 -1.279562 -0.822707  ... -1.662163 -0.527654  0.490121   \n",
            "1133087  2.590468  4.230633 -0.135628  ... -1.202482  0.089955 -0.219338   \n",
            "1133088 -0.249211  0.372138  0.744965  ... -3.331892 -0.181066 -0.435475   \n",
            "1133089 -0.471045  0.470695  1.576622  ...  0.061527 -0.447854  0.348796   \n",
            "\n",
            "             PC39      PC40      PC41      PC42      PC43      PC44  v16  \n",
            "0        1.655847 -0.511053  0.714753 -0.367519 -0.497544 -0.302017  0.0  \n",
            "1        0.656702 -0.181948  0.161404  0.173398  0.272636 -0.011590  0.0  \n",
            "2        0.993933 -0.277549  0.204464 -0.304442 -0.721791 -0.121767  0.0  \n",
            "3       -0.113488  0.023775 -0.051310  0.310832  0.478194  0.241764  0.0  \n",
            "4        2.079594 -0.674378 -0.523480  0.017366  0.536431 -0.025348  0.0  \n",
            "...           ...       ...       ...       ...       ...       ...  ...  \n",
            "1133085 -0.139746  0.076572  0.019072  0.763586  0.758910  0.331036  1.0  \n",
            "1133086  1.006917 -0.321164 -0.791698  0.429912  0.306614  0.148245  1.0  \n",
            "1133087 -0.084924  0.061387 -0.187037 -0.011411  0.033653  0.089391  1.0  \n",
            "1133088  0.458475 -0.021668  0.168362  0.102689  0.666230  0.055829  1.0  \n",
            "1133089 -0.005883  0.037659 -0.431348 -0.672045 -0.701412 -0.205041  1.0  \n",
            "\n",
            "[1133090 rows x 45 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "nan_check = final_df.isna().sum().sum()\n",
        "\n",
        "# If nan_check > 0, there are missing values in the dataset\n",
        "if nan_check > 0:\n",
        "    print(f\"The dataset contains {nan_check} missing values.\")\n",
        "else:\n",
        "    print(\"The dataset contains no missing values.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N84lovXRk1VZ",
        "outputId": "406537df-4bec-42d9-94f0-6f9dadf7ba92"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains no missing values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example: Assume 'data' is your DataFrame and 'target_column' is the column you want to check\n",
        "value_counts = final_df['v16'].value_counts()\n",
        "print(value_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLsZlMLVtWnb",
        "outputId": "bc8ae373-32bf-441a-ae06-a51ac4d2550a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v16\n",
            "0.0    566545\n",
            "1.0    566545\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# final_df1=test"
      ],
      "metadata": {
        "id": "1xn3JrRC4fPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Remove the target variable 'v16' if it exists\n",
        "data_without_target = data.drop(columns=['v16'], errors='ignore')\n",
        "\n",
        "# Identify non-numeric columns\n",
        "non_numeric_cols = data_without_target.select_dtypes(exclude=[int, float]).columns\n",
        "print(\"Non-numeric columns:\", non_numeric_cols)\n",
        "\n",
        "# Apply Label Encoding for non-numeric columns\n",
        "label_encoder = LabelEncoder()\n",
        "for col in non_numeric_cols:\n",
        "    data_without_target[col] = label_encoder.fit_transform(data_without_target[col])\n",
        "\n",
        "# Impute missing values in the dataset using the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_imputed = imputer.fit_transform(data_without_target)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_imputed)\n",
        "\n",
        "# Apply PCA to retain 95% of the variance\n",
        "pca = PCA(0.95)\n",
        "data_pca = pca.fit_transform(data_scaled)\n",
        "\n",
        "# Create a DataFrame with the principal components\n",
        "pca_columns = [f'PC{i+1}' for i in range(data_pca.shape[1])]\n",
        "data_pca_df = pd.DataFrame(data=data_pca, columns=pca_columns)\n",
        "\n",
        "# Combine with the original 'id' column if it exists\n",
        "if 'id' in data.columns:\n",
        "    final_df1 = pd.concat([data[['id']].reset_index(drop=True), data_pca_df], axis=1)\n",
        "else:\n",
        "    print(\"Warning: 'id' column not found in the original data. Proceeding without it.\")\n",
        "    final_df1 = data_pca_df\n",
        "\n",
        "# Output the final DataFrame\n",
        "print(final_df1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v0qFfCf0-PR",
        "outputId": "a0006837-0e7b-4524-9217-c2564178080d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-numeric columns: Index(['v15', 'v39', 'v41', 'v42'], dtype='object')\n",
            "            id       PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
            "0            1  1.432645 -0.944836 -1.075168 -0.808539 -0.292322 -1.958712   \n",
            "1            2 -2.035477 -1.778049  0.868146  0.873947 -0.002807 -0.064939   \n",
            "2            3  5.343929  2.460963  0.656341  1.147806 -0.089056 -2.395672   \n",
            "3            4  1.810176  3.296826  0.021966  0.300480 -0.149771 -1.026782   \n",
            "4            5  3.923146  0.778475  0.062735  0.265831  0.056479 -0.341798   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "186729  186730 -0.706463 -1.396845  1.504251  1.444677  0.161426  0.540021   \n",
            "186730  186731 -0.335514 -2.439772  0.482738  0.486245  0.097402  0.052223   \n",
            "186731  186732  0.177281  0.094525 -1.510632 -1.817764  0.157714 -0.105115   \n",
            "186732  186733 -0.017424  2.528710  0.905368  0.949250  0.047906 -0.310260   \n",
            "186733  186734  2.833654  1.776910  3.467190  3.628133  0.274323  1.096916   \n",
            "\n",
            "             PC7       PC8       PC9  ...      PC34      PC35      PC36  \\\n",
            "0      -0.029489 -1.192433  0.155545  ...  0.017011 -0.279802 -0.724920   \n",
            "1      -0.133071  0.292498  0.033963  ...  0.444471  0.468546 -0.442602   \n",
            "2       0.067988 -0.227901 -0.026483  ... -0.471142  0.044848 -0.198883   \n",
            "3       0.285526 -0.940144  0.670447  ...  0.224227 -0.237720  0.748640   \n",
            "4       0.107337 -0.081776  0.107048  ... -0.340051  0.560231  0.389106   \n",
            "...          ...       ...       ...  ...       ...       ...       ...   \n",
            "186729  0.100564  1.101124 -0.915459  ... -1.185485 -0.461367 -0.054941   \n",
            "186730 -0.156977  0.979145  0.153405  ... -1.586741  0.039791  0.641401   \n",
            "186731 -0.144902  0.176077 -1.606903  ...  0.433297 -1.137505  0.551466   \n",
            "186732  0.201234 -0.176575 -0.886906  ...  0.478995 -1.026223  0.667909   \n",
            "186733  0.192724  1.123108 -0.171062  ...  0.194996  0.481375  1.136967   \n",
            "\n",
            "            PC37      PC38      PC39      PC40      PC41      PC42      PC43  \n",
            "0       0.087867 -0.171456 -0.016014 -0.260450 -0.073161  0.175194 -0.071032  \n",
            "1       0.374325 -0.092490  0.055753  0.349078 -0.268777 -0.018878  0.009722  \n",
            "2      -0.556492  0.139632 -0.012764 -0.059833 -0.511070  0.177208  0.126413  \n",
            "3      -0.799077 -0.199756 -0.063317  0.181816 -0.549935 -0.097963 -0.009838  \n",
            "4      -0.264116 -0.096689 -0.019873 -0.358548  0.362635 -0.089174 -0.126723  \n",
            "...          ...       ...       ...       ...       ...       ...       ...  \n",
            "186729  0.712611 -0.532984 -0.067512 -0.317207  0.483909  0.093160 -0.154354  \n",
            "186730 -1.150436  0.468685 -0.068262  0.404801 -0.796368 -0.057823  0.157997  \n",
            "186731 -0.126917 -0.569348 -0.031432  0.247115 -0.115638  0.117398  0.115406  \n",
            "186732  0.922025 -0.783744 -0.022302 -0.039757  0.732138  0.199197 -0.109218  \n",
            "186733 -0.275983  0.071963 -0.006727  0.735135 -2.028939 -0.321425  0.442480  \n",
            "\n",
            "[186734 rows x 44 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply random forest algorithm"
      ],
      "metadata": {
        "id": "jZPAbC2P4kXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming `final_df` is your training data and `final_df1` is your testing data\n",
        "\n",
        "# Split `final_df` into features (X_train) and target (y_train)\n",
        "X_train = final_df.drop(columns=['v16'], errors='ignore')  # Drop target column from training data\n",
        "y_train = final_df['v16']  # Target variable\n",
        "\n",
        "# Split `final_df1` into features (X_test)\n",
        "X_test = final_df1  # Test data (only features, no target column in `final_df1`)\n",
        "\n",
        "# Initialize RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "# Since `final_df1` doesn't contain the true target labels, we'll use the predicted results directly.\n",
        "print(\"Predictions on the test data:\", y_pred)\n",
        "\n",
        "# Optionally, if you have a target variable in `final_df1` for evaluation, you could check accuracy\n",
        "# For example:\n",
        "# y_test = final_df1['v16']  # True labels in the test data (if available)\n",
        "# print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "_yN4Re3T0-M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GiaTjNgFuzJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S2_6hNmSuzGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQuY8VdTtIiv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}